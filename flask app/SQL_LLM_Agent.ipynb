{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7R_afDZmX9Mc",
        "outputId": "7d667f80-a181-42a4-ba66-dbe2cb2e2cee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.59.9)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.11/dist-packages (2.0.37)\n",
            "Collecting pyodbc\n",
            "  Downloading pyodbc-5.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy) (3.1.1)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading pyodbc-5.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (346 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.2/346.2 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyodbc\n",
            "Successfully installed pyodbc-5.2.0\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.11/dist-packages (2.0.37)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy) (4.12.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.55.7)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Requirement already satisfied: pyodbc in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.11/dist-packages (2.0.37)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.59.9)\n",
            "Collecting ngrok\n",
            "  Downloading ngrok-1.4.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.5)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy) (4.12.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading ngrok-1.4.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: pyngrok, ngrok\n",
            "Successfully installed ngrok-1.4.0 pyngrok-7.2.3\n"
          ]
        }
      ],
      "source": [
        "%pip install openai sqlalchemy pyodbc pandas\n",
        "%pip install sqlalchemy\n",
        "%pip install matplotlib seaborn\n",
        "%pip install flask pyodbc pandas sqlalchemy openai ngrok pyngrok\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cPvHbBIftwp"
      },
      "source": [
        "## Test DB Coneection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JRi-Q6XZV9L",
        "outputId": "c784f725-95ed-4912-a448-0ba8f9c54d50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   983  100   983    0     0   4176      0 --:--:-- --:--:-- --:--:--  4182\n",
            "Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n",
            "OK\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100    88  100    88    0     0    887      0 --:--:-- --:--:-- --:--:--   880\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 https://packages.microsoft.com/ubuntu/22.04/prod jammy InRelease [3,632 B]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,306 kB]\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:7 https://packages.microsoft.com/ubuntu/22.04/prod jammy/main arm64 Packages [44.5 kB]\n",
            "Get:8 https://packages.microsoft.com/ubuntu/22.04/prod jammy/main armhf Packages [16.9 kB]\n",
            "Get:9 https://packages.microsoft.com/ubuntu/22.04/prod jammy/main all Packages [1,243 B]\n",
            "Get:10 https://packages.microsoft.com/ubuntu/22.04/prod jammy/main amd64 Packages [181 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:14 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:16 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,647 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,604 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,904 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,229 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,521 kB]\n",
            "Get:22 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,640 kB]\n",
            "Fetched 21.5 MB in 7s (2,939 kB/s)\n",
            "Reading package lists... Done\n",
            "W: https://packages.microsoft.com/ubuntu/22.04/prod/dists/jammy/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  odbcinst unixodbc\n",
            "The following NEW packages will be installed:\n",
            "  msodbcsql17 odbcinst unixodbc\n",
            "0 upgraded, 3 newly installed, 0 to remove and 24 not upgraded.\n",
            "Need to get 783 kB of archives.\n",
            "After this operation, 164 kB of additional disk space will be used.\n",
            "Get:1 https://packages.microsoft.com/ubuntu/22.04/prod jammy/main amd64 msodbcsql17 amd64 17.10.6.1-1 [746 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 odbcinst amd64 2.3.9-5ubuntu0.1 [9,930 B]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 unixodbc amd64 2.3.9-5ubuntu0.1 [26.7 kB]\n",
            "Fetched 783 kB in 1s (931 kB/s)\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package odbcinst.\n",
            "(Reading database ... 124950 files and directories currently installed.)\n",
            "Preparing to unpack .../odbcinst_2.3.9-5ubuntu0.1_amd64.deb ...\n",
            "Unpacking odbcinst (2.3.9-5ubuntu0.1) ...\n",
            "Selecting previously unselected package unixodbc.\n",
            "Preparing to unpack .../unixodbc_2.3.9-5ubuntu0.1_amd64.deb ...\n",
            "Unpacking unixodbc (2.3.9-5ubuntu0.1) ...\n",
            "Selecting previously unselected package msodbcsql17.\n",
            "Preparing to unpack .../msodbcsql17_17.10.6.1-1_amd64.deb ...\n",
            "Unpacking msodbcsql17 (17.10.6.1-1) ...\n",
            "Setting up odbcinst (2.3.9-5ubuntu0.1) ...\n",
            "Setting up unixodbc (2.3.9-5ubuntu0.1) ...\n",
            "Setting up msodbcsql17 (17.10.6.1-1) ...\n",
            "odbcinst: Driver installed. Usage count increased to 1. \n",
            "    Target directory is /etc\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "unixodbc-dev is already the newest version (2.3.9-5ubuntu0.1).\n",
            "unixodbc-dev set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "# Install the ODBC Driver 17 for SQL Server\n",
        "!curl https://packages.microsoft.com/keys/microsoft.asc | apt-key add -\n",
        "!curl https://packages.microsoft.com/config/ubuntu/$(lsb_release -rs)/prod.list > /etc/apt/sources.list.d/mssql-release.list\n",
        "!apt-get update\n",
        "!ACCEPT_EULA=Y apt-get install -y msodbcsql17\n",
        "!apt-get install -y unixodbc-dev\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6bcpLrvZZso",
        "outputId": "b7ec59aa-458d-4922-bf27-df4dce8481c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ODBC Driver 17 for SQL Server]\n",
            "Description=Microsoft ODBC Driver 17 for SQL Server\n",
            "Driver=/opt/microsoft/msodbcsql17/lib64/libmsodbcsql-17.10.so.6.1\n",
            "UsageCount=1\n"
          ]
        }
      ],
      "source": [
        "# Check if the ODBC Driver 17 is installed\n",
        "!odbcinst -q -d -n \"ODBC Driver 17 for SQL Server\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oH0sF8hsYKJ3",
        "outputId": "9453cffb-f915-41b6-9247-f72c0d0342ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connection successful!\n",
            "Query executed successfully: 1\n"
          ]
        }
      ],
      "source": [
        "import pyodbc\n",
        "# Connection string\n",
        "server = \"\"\n",
        "database = \"SQL-LLm\"\n",
        "username = \"\"\n",
        "password = \"\"  # Replace with your actual password\n",
        "driver = \"{ODBC Driver 17 for SQL Server}\"\n",
        "conn_str = f\"DRIVER={driver};SERVER={server};DATABASE={database};UID={username};PWD={password};Encrypt=yes;TrustServerCertificate=no;Connection Timeout=30;\"\n",
        "\n",
        "try:\n",
        "    # Attempt to connect to the database\n",
        "    conn = pyodbc.connect(conn_str)\n",
        "    print(\"Connection successful!\")\n",
        "\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"SELECT 1\")\n",
        "    row = cursor.fetchone()\n",
        "    if row:\n",
        "        print(\"Query executed successfully:\", row[0])\n",
        "    # Close the connection\n",
        "    conn.close()\n",
        "\n",
        "except pyodbc.Error as e:\n",
        "    print(\"Connection failed. Error:\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUK8OKErYR4-"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    # Attempt to connect to the database\n",
        "    conn = pyodbc.connect(conn_str)\n",
        "    print(\"Connection successful!\")\n",
        "\n",
        "    # Execute a query to select all rows from the Sales_fact table\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"SELECT * FROM Sales_fact\")\n",
        "\n",
        "    # Fetch all rows\n",
        "    rows = cursor.fetchall()\n",
        "\n",
        "    # Print the results\n",
        "    for row in rows:\n",
        "        print(row)\n",
        "\n",
        "    # Close the connection\n",
        "    conn.close()\n",
        "\n",
        "except pyodbc.Error as e:\n",
        "    print(\"Query execution failed. Error:\", e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEhjEyPF8iir"
      },
      "source": [
        "## 2. With modification SQL\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GR22wtX0qasL",
        "outputId": "42935724-ce8f-480f-c3da-0e40a6a4bdd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Public URL: https://1a67-35-234-51-197.ngrok-free.app\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated SQL: SELECT TOP 5 c.customer_name, SUM(sf.total_amount) AS total_sales\n",
            "FROM Sales_Fact sf\n",
            "INNER JOIN Customers_Dim c ON sf.customer_id = c.customer_id\n",
            "GROUP BY c.customer_name\n",
            "ORDER BY total_sales DESC;\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [31/Jan/2025 14:48:05] \"POST /query HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Executing Modified SQL: SELECT TOP 5 c.customer_name, SUM(sf.total_amount) AS total_sales\n",
            "FROM Sales_Fact sf\n",
            "INNER JOIN Customers_Dim c ON sf.customer_id = c.customer_id\n",
            "GROUP BY c.customer_name\n",
            "ORDER BY total_sales DESC;\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [31/Jan/2025 14:48:11] \"POST /query HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated SQL: SELECT t.quarter, t.year, SUM(sf.total_amount) AS total_sales, \n",
            "    (SUM(sf.total_amount) - LAG(SUM(sf.total_amount)) OVER (ORDER BY t.year, t.quarter)) / LAG(SUM(sf.total_amount)) OVER (ORDER BY t.year, t.quarter) AS growth_rate\n",
            "FROM Sales_Fact sf\n",
            "INNER JOIN Time_Dim t ON sf.time_id = t.time_id\n",
            "WHERE t.year >= YEAR(GETDATE()) - 2\n",
            "GROUP BY t.quarter, t.year\n",
            "ORDER BY t.year, t.quarter;\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [31/Jan/2025 14:48:47] \"POST /query HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Executing Modified SQL: SELECT t.quarter, t.year, SUM(sf.total_amount) AS total_sales, \n",
            "    (SUM(sf.total_amount) - LAG(SUM(sf.total_amount)) OVER (ORDER BY t.year, t.quarter)) / LAG(SUM(sf.total_amount)) OVER (ORDER BY t.year, t.quarter) AS growth_rate\n",
            "FROM Sales_Fact sf\n",
            "INNER JOIN Time_Dim t ON sf.time_id = t.time_id\n",
            "WHERE t.year >= YEAR(GETDATE()) - 2\n",
            "GROUP BY t.quarter, t.year\n",
            "ORDER BY t.year, t.quarter;\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [31/Jan/2025 14:48:53] \"POST /query HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated SQL: SELECT c.region, SUM(sf.total_amount) AS top_sales\n",
            "FROM Sales_Fact sf\n",
            "INNER JOIN Customers_Dim c ON sf.customer_id = c.customer_id\n",
            "INNER JOIN Time_Dim t ON sf.time_id = t.time_id\n",
            "WHERE t.year >= YEAR(GETDATE()) - 3\n",
            "GROUP BY c.region\n",
            "ORDER BY top_sales DESC;\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [31/Jan/2025 14:49:30] \"POST /query HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Executing Modified SQL: SELECT c.region, SUM(sf.total_amount) AS top_sales\n",
            "FROM Sales_Fact sf\n",
            "INNER JOIN Customers_Dim c ON sf.customer_id = c.customer_id\n",
            "INNER JOIN Time_Dim t ON sf.time_id = t.time_id\n",
            "WHERE t.year >= YEAR(GETDATE()) - 3\n",
            "GROUP BY c.region\n",
            "ORDER BY top_sales DESC;\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [31/Jan/2025 14:49:37] \"POST /query HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated SQL: SELECT c.region, SUM(sf.total_amount) AS total_sales\n",
            "FROM Sales_Fact sf\n",
            "INNER JOIN Customers_Dim c ON sf.customer_id = c.customer_id\n",
            "INNER JOIN Time_Dim t ON sf.time_id = t.time_id\n",
            "WHERE t.year >= YEAR(GETDATE()) - 3\n",
            "GROUP BY c.region\n",
            "ORDER BY total_sales DESC;\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [31/Jan/2025 14:51:11] \"POST /query HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Executing Modified SQL: SELECT c.region, SUM(sf.total_amount) AS total_sales\n",
            "FROM Sales_Fact sf\n",
            "INNER JOIN Customers_Dim c ON sf.customer_id = c.customer_id\n",
            "INNER JOIN Time_Dim t ON sf.time_id = t.time_id\n",
            "WHERE t.year >= YEAR(GETDATE()) - 4\n",
            "GROUP BY c.region\n",
            "ORDER BY total_sales DESC;\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [31/Jan/2025 14:51:24] \"POST /query HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Executing Modified SQL: SELECT c.region, SUM(sf.total_amount) AS total_sales\n",
            "FROM Sales_Fact sf\n",
            "INNER JOIN Customers_Dim c ON sf.customer_id = c.customer_id\n",
            "INNER JOIN Time_Dim t ON sf.time_id = t.time_id\n",
            "WHERE t.year >= YEAR(GETDATE()) - 3\n",
            "GROUP BY c.region\n",
            "ORDER BY total_sales DESC;\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [31/Jan/2025 14:51:45] \"POST /query HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated SQL: SELECT c.region, SUM(sf.total_amount) AS top_sales\n",
            "FROM Sales_Fact sf\n",
            "INNER JOIN Customers_Dim c ON sf.customer_id = c.customer_id\n",
            "INNER JOIN Time_Dim t ON sf.time_id = t.time_id\n",
            "WHERE t.year >= YEAR(GETDATE()) - 3\n",
            "GROUP BY c.region\n",
            "ORDER BY top_sales DESC;\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [31/Jan/2025 15:02:13] \"POST /query HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Executing Modified SQL: SELECT c.region, SUM(sf.total_amount) AS top_sales\n",
            "FROM Sales_Fact sf\n",
            "INNER JOIN Customers_Dim c ON sf.customer_id = c.customer_id\n",
            "INNER JOIN Time_Dim t ON sf.time_id = t.time_id\n",
            "WHERE t.year >= YEAR(GETDATE()) - 3\n",
            "GROUP BY c.region\n",
            "ORDER BY top_sales DESC;\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [31/Jan/2025 15:02:23] \"POST /query HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Executing Modified SQL: SELECT c.region, SUM(sf.total_amount) AS top_sales\n",
            "FROM Sales_Fact sf\n",
            "INNER JOIN Customers_Dim c ON sf.customer_id = c.customer_id\n",
            "INNER JOIN Time_Dim t ON sf.time_id = t.time_id\n",
            "WHERE t.year >= YEAR(GETDATE()) - 5\n",
            "GROUP BY c.region\n",
            "ORDER BY top_sales DESC;\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [31/Jan/2025 15:02:40] \"POST /query HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Executing Modified SQL: SELECT c.region, SUM(sf.total_amount) AS top_sales\n",
            "FROM Sales_Fact sf\n",
            "INNER JOIN Customers_Dim c ON sf.customer_id = c.customer_id\n",
            "INNER JOIN Time_Dim t ON sf.time_id = t.time_id\n",
            "WHERE t.year >= YEAR(GETDATE()) - 2\n",
            "GROUP BY c.region\n",
            "ORDER BY top_sales DESC;\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [31/Jan/2025 15:02:54] \"POST /query HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Executing Modified SQL: SELECT c.region, SUM(sf.total_amount) AS top_sales\n",
            "FROM Sales_Fact sf\n",
            "INNER JOIN Customers_Dim c ON sf.customer_id = c.customer_id\n",
            "INNER JOIN Time_Dim t ON sf.time_id = t.time_id\n",
            "WHERE t.year >= YEAR(GETDATE()) - 3\n",
            "GROUP BY c.region\n",
            "ORDER BY top_sales DESC;\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [31/Jan/2025 15:03:32] \"POST /query HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated SQL: SELECT TOP 3 SUM(sf.total_amount) AS total_sales, c.region\n",
            "FROM Sales_Fact sf\n",
            "INNER JOIN Customers_Dim c ON sf.customer_id = c.customer_id\n",
            "INNER JOIN Time_Dim t ON sf.time_id = t.time_id\n",
            "WHERE t.year >= YEAR(GETDATE()) - 3\n",
            "GROUP BY c.region\n",
            "ORDER BY total_sales DESC;\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [31/Jan/2025 15:03:44] \"POST /query HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Executing Modified SQL: SELECT TOP 3 SUM(sf.total_amount) AS total_sales, c.region\n",
            "FROM Sales_Fact sf\n",
            "INNER JOIN Customers_Dim c ON sf.customer_id = c.customer_id\n",
            "INNER JOIN Time_Dim t ON sf.time_id = t.time_id\n",
            "WHERE t.year >= YEAR(GETDATE()) - 3\n",
            "GROUP BY c.region\n",
            "ORDER BY total_sales DESC;\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [31/Jan/2025 15:03:51] \"POST /query HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Executing Modified SQL: SELECT TOP 5 SUM(sf.total_amount) AS total_sales, c.region\n",
            "FROM Sales_Fact sf\n",
            "INNER JOIN Customers_Dim c ON sf.customer_id = c.customer_id\n",
            "INNER JOIN Time_Dim t ON sf.time_id = t.time_id\n",
            "WHERE t.year >= YEAR(GETDATE()) - 3\n",
            "GROUP BY c.region\n",
            "ORDER BY total_sales DESC;\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [31/Jan/2025 15:04:03] \"POST /query HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated SQL: SELECT TOP 3 SUM(sf.total_amount) AS total_sales, c.region\n",
            "FROM Sales_Fact sf\n",
            "INNER JOIN Customers_Dim c ON sf.customer_id = c.customer_id\n",
            "INNER JOIN Time_Dim t ON sf.time_id = t.time_id\n",
            "WHERE t.year >= YEAR(GETDATE()) - 3\n",
            "GROUP BY c.region\n",
            "ORDER BY total_sales DESC;\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [31/Jan/2025 15:04:25] \"POST /query HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Executing Modified SQL: SELECT TOP 3 SUM(sf.total_amount) AS total_sales, c.region\n",
            "FROM Sales_Fact sf\n",
            "INNER JOIN Customers_Dim c ON sf.customer_id = c.customer_id\n",
            "INNER JOIN Time_Dim t ON sf.time_id = t.time_id\n",
            "WHERE t.year >= YEAR(GETDATE()) - 3\n",
            "GROUP BY c.region\n",
            "ORDER BY total_sales DESC;\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [31/Jan/2025 15:04:34] \"POST /query HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Executing Modified SQL: SELECT TOP 5 SUM(sf.total_amount) AS total_sales, c.region\n",
            "FROM Sales_Fact sf\n",
            "INNER JOIN Customers_Dim c ON sf.customer_id = c.customer_id\n",
            "INNER JOIN Time_Dim t ON sf.time_id = t.time_id\n",
            "WHERE t.year >= YEAR(GETDATE()) - 3\n",
            "GROUP BY c.region\n",
            "ORDER BY total_sales DESC;\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [31/Jan/2025 15:04:52] \"POST /query HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated SQL: SELECT TOP 3 SUM(sf.total_amount) AS total_sales, c.region\n",
            "FROM Sales_Fact sf\n",
            "INNER JOIN Customers_Dim c ON sf.customer_id = c.customer_id\n",
            "INNER JOIN Time_Dim t ON sf.time_id = t.time_id\n",
            "WHERE t.year >= YEAR(GETDATE()) - 3\n",
            "GROUP BY c.region\n",
            "ORDER BY total_sales DESC;\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [31/Jan/2025 15:09:37] \"POST /query HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Executing Modified SQL: SELECT TOP 5 SUM(sf.total_amount) AS total_sales, c.region\n",
            "FROM Sales_Fact sf\n",
            "INNER JOIN Customers_Dim c ON sf.customer_id = c.customer_id\n",
            "INNER JOIN Time_Dim t ON sf.time_id = t.time_id\n",
            "WHERE t.year >= YEAR(GETDATE()) - 3\n",
            "GROUP BY c.region\n",
            "ORDER BY total_sales DESC;\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [31/Jan/2025 15:10:25] \"POST /query HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Executing Modified SQL: SELECT TOP 5 SUM(sf.total_amount) AS total_sales, c.region\n",
            "FROM Sales_Fact sf\n",
            "INNER JOIN Customers_Dim c ON sf.customer_id = c.customer_id\n",
            "INNER JOIN Time_Dim t ON sf.time_id = t.time_id\n",
            "WHERE t.year >= YEAR(GETDATE()) - 3\n",
            "GROUP BY c.region\n",
            "ORDER BY total_sales DESC;\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [31/Jan/2025 15:36:52] \"\u001b[35m\u001b[1mPOST /query HTTP/1.1\u001b[0m\" 500 -\n"
          ]
        }
      ],
      "source": [
        "from flask import Flask, request, jsonify\n",
        "import os\n",
        "from openai import AzureOpenAI\n",
        "import pandas as pd\n",
        "from sqlalchemy import create_engine\n",
        "from pyngrok import ngrok\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# ngrok authtoken\n",
        "ngrok.set_auth_token(\"<Ngrok Token>\")\n",
        "\n",
        "# Azure OpenAI\n",
        "client = AzureOpenAI(\n",
        "    api_key=\"<Your Azure API Key>\",\n",
        "    api_version=\"2024-02-01\",\n",
        "    azure_endpoint=\"\"\n",
        ")\n",
        "\n",
        "# Azure SQL Server settings\n",
        "server = \"\"\n",
        "database = \"SQL-LLm\"\n",
        "username = \"\"\n",
        "password = \"\"\n",
        "driver = \"ODBC Driver 17 for SQL Server\"\n",
        "\n",
        "deployment_name = \"gpt-35-turbo-instruct\"\n",
        "\n",
        "# generate SQL using Azure OpenAI\n",
        "def generate_sql(question):\n",
        "    prompt = f\"\"\"\n",
        "You are an expert in SQL using Microsoft SQL Server assistant. Based on the given schema and relationships, generate an optimized SQL query.\n",
        "\n",
        "Tables:\n",
        "- Sales_Fact: sales_id, product_id, customer_id, time_id, quantity_sold, total_amount\n",
        "- Products_Dim: product_id, product_name, category, price\n",
        "- Customers_Dim: customer_id, customer_name, region, country\n",
        "- Time_Dim: time_id, date, month, quarter, year\n",
        "\n",
        "Relationships:\n",
        "- Sales_Fact.product_id -> Products_Dim.product_id\n",
        "- Sales_Fact.customer_id -> Customers_Dim.customer_id\n",
        "- Sales_Fact.time_id -> Time_Dim.time_id\n",
        "\n",
        "Question: {question}\n",
        "SQL Query:\n",
        "\"\"\"\n",
        "    response = client.completions.create(\n",
        "        model=deployment_name,\n",
        "        prompt=prompt,\n",
        "        temperature=0.1,  # Lower temperature for more deterministic results\n",
        "        max_tokens=200,  # Increase max_tokens for longer queries\n",
        "        top_p=0.5,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0,\n",
        "        best_of=1,\n",
        "        stop=None\n",
        "    )\n",
        "    return response.choices[0].text.strip()\n",
        "\n",
        "# to execute SQL and return results\n",
        "def execute_sql(sql_query):\n",
        "    connection_string = f\"mssql+pyodbc://{username}:{password}@{server}/{database}?driver={driver.replace(' ', '+')}\"\n",
        "    engine = create_engine(connection_string)\n",
        "\n",
        "    df = pd.read_sql(sql_query, engine)\n",
        "    return df\n",
        "\n",
        "# API endpoint to handle questions and modified SQL queries\n",
        "@app.route('/query', methods=['POST'])\n",
        "def handle_query():\n",
        "    data = request.json\n",
        "    question = data.get('question')\n",
        "    sql_query = data.get('sql_query')  # Get the modified SQL query from the request\n",
        "\n",
        "    if not question and not sql_query:\n",
        "        return jsonify({\"error\": \"Question or SQL query is required\"}), 400\n",
        "\n",
        "    try:\n",
        "        if question:\n",
        "            # Generate SQL query from the question\n",
        "            sql_query = generate_sql(question)\n",
        "            print(\"Generated SQL:\", sql_query)\n",
        "        elif sql_query:\n",
        "            print(\"Executing Modified SQL:\", sql_query)\n",
        "\n",
        "        # Execute SQL query\n",
        "        result = execute_sql(sql_query)\n",
        "\n",
        "        result_json = result.to_json(orient='records')\n",
        "        return jsonify({\"sql_query\": sql_query, \"result\": result_json})\n",
        "\n",
        "    except Exception as e:\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    ngrok_tunnel = ngrok.connect(5000)\n",
        "    print(\"Public URL:\", ngrok_tunnel.public_url)\n",
        "    app.run()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPcO9n2KhmIY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "8cPvHbBIftwp"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
